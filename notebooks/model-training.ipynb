{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f2acea",
   "metadata": {},
   "source": [
    "# Model Training Pipeline\n",
    "In the model selection notebook (`model-selection.ipynb`), we tested out a number of different algorithms to support the binary classification and regression models. This notebook will take the final candidates from that notebook to craft a full training pipeline. This full training pipeline will not only perform model training but will also incorporate feature engineering. At the end of this notebook, we will produce two serialized models in `.pkl` form: one for the binary classification model and the other for the regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d6e705",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0aa0b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary Python libraries\n",
    "import cloudpickle\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Hiding any warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Adjusting Pandas output\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b19d1243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in the training data\n",
    "df_raw = pd.read_csv('../data/raw/all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48b9da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping any movies with no \"ground truth\" review\n",
    "df_raw.drop(df_raw.index[df_raw['biehn_scale_rating'].isnull()], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8627e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing the encoding of the \"biehn_yes_or_no\" predictor feature\n",
    "for index, row in df_raw.iterrows():\n",
    "    movie_name = row['movie_name']\n",
    "    if row['biehn_yes_or_no'] == 'Yes':\n",
    "        df_raw.loc[index, 'biehn_yes_or_no'] = 1\n",
    "    elif row['biehn_yes_or_no'] == 'No':\n",
    "        df_raw.loc[index, 'biehn_yes_or_no'] = 0\n",
    "        \n",
    "# Changing the datatype of the 'biehn_yes_or_no' to int\n",
    "df_raw['biehn_yes_or_no'] = df_raw['biehn_yes_or_no'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382f4fa8",
   "metadata": {},
   "source": [
    "## Feature Engineering Helper Functions\n",
    "As we create our full model training pipeline, we are going to need to do some feature engineering on the raw data. These helper functions in this section contain custom code that we can then apply to the full training pipeline so that we can engineer data from something more raw (unclean) to something that our model can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9826d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a helper function to engineer the \"movie_age\" feature\n",
    "def generate_movie_age(df):\n",
    "    \"\"\"\n",
    "    Generating a movie age relative to the current year and the year that the movie was released\n",
    "\n",
    "    Args:\n",
    "        - df (Pandas DataFrame): A DataFrame containing the raw data for which year the movie was released\n",
    "\n",
    "    Returns:\n",
    "        - df (Pandas DataFrame): A DataFrame containing newly engineered feature of relative \"year\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extracting current year\n",
    "    currentYear = datetime.now().year\n",
    "    \n",
    "    # Engineering the \"year\" column to be a relative \"movie_age\" column based on number of years since original release\n",
    "    for index, row in df.iterrows():\n",
    "        year_released = row['year']\n",
    "        movie_age = currentYear - year_released\n",
    "        df.loc[index, 'movie_age'] = movie_age\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cb8cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a helper function to perform feature engineering on RT critic score\n",
    "def engineer_rt_critic_score(df):\n",
    "    \"\"\"\n",
    "    Feature engineering the Rotten Tomatoes critic score\n",
    "\n",
    "    Args:\n",
    "        - df (Pandas DataFrame): A DataFrame containing the raw data RT critic score\n",
    "\n",
    "    Returns:\n",
    "        - df (Pandas DataFrame): A DataFrame containing an updated version of RT critic score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Removing percentage sign from RT critic score\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notnull(row['rt_critic_score']):\n",
    "            df.loc[index, 'rt_critic_score'] = int(row['rt_critic_score'][:2])\n",
    "    \n",
    "    # Filling rt_critic_score nulls with critic average of 59%\n",
    "    df['rt_critic_score'].fillna(59, inplace = True)\n",
    "    \n",
    "    # Transforming RT critic score into an integer datatype\n",
    "    df['rt_critic_score'] = df['rt_critic_score'].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f805b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a helper function to handle nulls for the metascore feature\n",
    "def handle_nulls_for_metascore(df):\n",
    "    \"\"\"\n",
    "    Handling the nulls associated to the metascore feature\n",
    "\n",
    "    Args:\n",
    "        - df (Pandas DataFrame): A DataFrame containing the raw data metascore feature\n",
    "\n",
    "    Returns:\n",
    "        - df (Pandas DataFrame): A DataFrame containing an updated version of the metascore\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filling metascore nulls with 50.0\n",
    "    df['metascore'].fillna(50.0, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c52a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a helper function to handle nulls for the RT audience feature\n",
    "def handle_nulls_for_rt_audience_score(df):\n",
    "    \"\"\"\n",
    "    Handling the nulls associated to the RT audience score feature\n",
    "\n",
    "    Args:\n",
    "        - df (Pandas DataFrame): A DataFrame containing the raw data RT audience score feature\n",
    "\n",
    "    Returns:\n",
    "        - df (Pandas DataFrame): A DataFrame containing an updated version of the RT audience score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filling rt_audience_score with audience average of 59%\n",
    "    df['rt_audience_score'].fillna(59.0, inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a57ea6",
   "metadata": {},
   "source": [
    "## Pipeline Creation\n",
    "\n",
    "Now that we have created our helper functions to perform the feature engineering, we are ready to begin packaging everything as a single, unified pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69aef3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the data preprocessor that will perform our feature engineering\n",
    "data_preprocessor = ColumnTransformer(transformers = [\n",
    "    ('ohe_engineering', OneHotEncoder(use_cat_names = True, handle_unknown = 'ignore'), ['primary_genre', 'secondary_genre']),\n",
    "    ('movie_age_engineering', FunctionTransformer(generate_movie_age, validate = False), ['year']),\n",
    "    ('rt_critic_score_engineering', FunctionTransformer(engineer_rt_critic_score, validate = False), ['rt_critic_score']),\n",
    "    ('rt_audience_score_engineering', FunctionTransformer(handle_nulls_for_rt_audience_score, validate = False), ['rt_audience_score']),    \n",
    "    ('metascore_engineering', FunctionTransformer(handle_nulls_for_metascore, validate = False), ['metascore']),\n",
    "    ('columns_to_drop', 'drop', ['movie_name', 'tmdb_id', 'imdb_id', 'tmdb_popularity'])\n",
    "],\n",
    "    remainder = 'passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2387a00",
   "metadata": {},
   "source": [
    "### Training the Binary Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e6bf025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the predictor value from the remainder of the dataset\n",
    "X = df_raw.drop(columns = ['biehn_yes_or_no', 'biehn_scale_rating'])\n",
    "y = df_raw[['biehn_yes_or_no']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5390090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the full inference pipeline for the binary classification model\n",
    "binary_classification_pipeline = Pipeline(steps = [\n",
    "    ('feature_engineering', data_preprocessor),\n",
    "    ('predictive_modeling', RandomForestClassifier(n_estimators = 50,\n",
    "                                                   max_depth = 20,\n",
    "                                                   min_samples_split = 5,\n",
    "                                                   min_samples_leaf = 2))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "310617b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_engineering',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe_engineering',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                use_cat_names=True),\n",
       "                                                  ['primary_genre',\n",
       "                                                   'secondary_genre']),\n",
       "                                                 ('movie_age_engineering',\n",
       "                                                  FunctionTransformer(func=<function generate_movie_age at 0x7f85d9b73700>),\n",
       "                                                  ['year']),\n",
       "                                                 ('rt_critic_score_engineering',\n",
       "                                                  Func...\n",
       "                                                  FunctionTransformer(func=<function handle_nulls_for_rt_audience_score at 0x7f85e8b8d4c0>),\n",
       "                                                  ['rt_audience_score']),\n",
       "                                                 ('metascore_engineering',\n",
       "                                                  FunctionTransformer(func=<function handle_nulls_for_metascore at 0x7f85e8b8d040>),\n",
       "                                                  ['metascore']),\n",
       "                                                 ('columns_to_drop', 'drop',\n",
       "                                                  ['movie_name', 'tmdb_id',\n",
       "                                                   'imdb_id',\n",
       "                                                   'tmdb_popularity'])])),\n",
       "                ('predictive_modeling',\n",
       "                 RandomForestClassifier(max_depth=20, min_samples_leaf=2,\n",
       "                                        min_samples_split=5,\n",
       "                                        n_estimators=50))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formally training the binary classification pipeline\n",
    "binary_classification_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b81d95b",
   "metadata": {},
   "source": [
    "### Training the Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2163c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the predictor value from the remainder of the dataset\n",
    "X = df_raw.drop(columns = ['biehn_yes_or_no', 'biehn_scale_rating'])\n",
    "y = df_raw[['biehn_scale_rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf6d52f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating a StandardScaler object for feature scaling\n",
    "feature_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cc07184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the full inference pipeline for the binary classification model\n",
    "regression_pipeline = Pipeline(steps = [\n",
    "    ('feature_engineering', data_preprocessor),\n",
    "    ('feature_scaling', feature_scaler),\n",
    "    ('predictive_modeling', Lasso(alpha = 0.275))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d7d3be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('feature_engineering',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('ohe_engineering',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                use_cat_names=True),\n",
       "                                                  ['primary_genre',\n",
       "                                                   'secondary_genre']),\n",
       "                                                 ('movie_age_engineering',\n",
       "                                                  FunctionTransformer(func=<function generate_movie_age at 0x7f85d9b73700>),\n",
       "                                                  ['year']),\n",
       "                                                 ('rt_critic_score_engineering',\n",
       "                                                  Func...\n",
       "                                                  FunctionTransformer(func=<function handle_nulls_for_rt_audience_score at 0x7f85e8b8d4c0>),\n",
       "                                                  ['rt_audience_score']),\n",
       "                                                 ('metascore_engineering',\n",
       "                                                  FunctionTransformer(func=<function handle_nulls_for_metascore at 0x7f85e8b8d040>),\n",
       "                                                  ['metascore']),\n",
       "                                                 ('columns_to_drop', 'drop',\n",
       "                                                  ['movie_name', 'tmdb_id',\n",
       "                                                   'imdb_id',\n",
       "                                                   'tmdb_popularity'])])),\n",
       "                ('feature_scaling', StandardScaler()),\n",
       "                ('predictive_modeling', Lasso(alpha=0.275))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formally training the regression pipeline\n",
    "regression_pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b56949",
   "metadata": {},
   "source": [
    "### Saving the Serialized Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d352ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the binary classification pipeline to a serialized pickle file\n",
    "with open('../models/binary_classification_pipeline.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(binary_classification_pipeline, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "34001656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the regression pipeline to a serialized pickle file\n",
    "with open('../models/regression_pipeline.pkl', 'wb') as f:\n",
    "    cloudpickle.dump(regression_pipeline, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
